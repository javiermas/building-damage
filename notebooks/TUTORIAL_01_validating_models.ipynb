{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Validating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we can see how to validate models. Note that it requires to have run the TUTORIAL_00 notebook first so we precompute the features that will be used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "from damage.data import DataStream\n",
    "from damage.models import CNN, RandomSearch, CNNPreTrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "RESULTS_PATH = '../logs/experiments'\n",
    "FEATURES_PATH = '../logs/features'\n",
    "features_file_name = 'example.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>damage_num</th>\n",
       "      <th>destroyed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"61\" valign=\"top\">aleppo</th>\n",
       "      <th>10016-10016</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.213510</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[189, 190, 189, 247, 243, 239], [197, 198, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10080</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.213166</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[173, 178, 181, 239, 239, 239], [173, 174, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10144</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.212823</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[140, 146, 148, 90, 105, 123], [140, 142, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10208</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.212480</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 113, 115, 197, 190, 181], [132, 130, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10272</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.212136</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[156, 154, 148, 66, 53, 41], [148, 142, 140,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10336</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.211793</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[156, 170, 181, 255, 255, 255], [148, 162, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10400</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.211450</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[99, 85, 90, 181, 166, 156], [115, 101, 99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10464</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.211106</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 89, 90, 123, 97, 90], [115, 85, 82, 90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10528</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.210763</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[74, 53, 49, 140, 109, 82], [82, 61, 58, 140...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10592</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.210420</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[58, 36, 33, 148, 130, 132], [82, 61, 58, 99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10656</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.210077</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[197, 194, 197, 123, 121, 123], [197, 194, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10720</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.209733</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[189, 194, 197, 74, 85, 82], [181, 190, 189,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10784</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.209390</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[140, 130, 132, 214, 202, 181], [140, 130, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10848</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.209047</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[181, 198, 214, 58, 61, 99], [181, 198, 214,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10912</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.208703</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[181, 198, 214, 247, 255, 255], [173, 194, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-10976</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.208360</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[66, 85, 82, 107, 89, 99], [74, 93, 90, 74, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11040</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.208017</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[140, 146, 156, 255, 239, 214], [140, 142, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11104</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.207673</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[82, 93, 107, 82, 85, 99], [74, 89, 107, 82,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11168</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.207330</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[206, 215, 222, 255, 255, 247], [214, 219, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11232</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.206987</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[140, 142, 148, 189, 182, 181], [132, 134, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11296</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.206643</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[49, 65, 74, 132, 138, 123], [58, 73, 82, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11360</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.206300</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 113, 123, 189, 166, 156], [123, 125, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11424</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.205957</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[107, 101, 99, 115, 109, 107], [107, 101, 99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11488</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.205613</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[132, 117, 115, 140, 125, 115], [123, 109, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11552</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.205270</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 101, 99, 140, 134, 123], [115, 97, 99,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11616</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.204927</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 101, 99, 206, 174, 165], [115, 101, 99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11680</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.204583</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 97, 90, 165, 130, 115], [115, 101, 99,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11744</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.204240</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[115, 97, 90, 148, 121, 99], [107, 97, 90, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11808</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.203897</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[49, 49, 41, 123, 130, 132], [99, 97, 82, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-11872</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.203553</td>\n",
       "      <td>37.120230</td>\n",
       "      <td>[[[197, 194, 189, 255, 231, 214], [206, 202, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8096</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.223809</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[189, 190, 181, 255, 255, 255], [181, 190, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8160</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.223466</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[123, 117, 115, 140, 138, 132], [107, 105, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8224</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.223123</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[58, 73, 74, 222, 215, 206], [58, 69, 66, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8288</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.222779</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[16, 24, 16, 247, 255, 247], [8, 16, 8, 189,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8352</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.222436</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[41, 45, 41, 99, 113, 107], [41, 40, 33, 82,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8416</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.222093</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[99, 113, 123, 156, 166, 165], [99, 113, 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8480</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.221749</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[49, 65, 82, 99, 117, 115], [41, 57, 82, 115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8544</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.221406</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[173, 166, 165, 189, 190, 189], [173, 170, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8608</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.221063</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[214, 215, 214, 255, 255, 255], [214, 215, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8672</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.220720</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[132, 142, 148, 132, 130, 132], [140, 146, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8736</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.220376</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[8, 16, 8, 115, 130, 148], [33, 40, 41, 41, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8800</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.220033</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[197, 206, 214, 107, 105, 99], [197, 210, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8864</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.219690</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[107, 93, 90, 156, 130, 123], [115, 97, 90, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8928</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.219346</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[66, 53, 49, 41, 53, 49], [82, 69, 66, 90, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-8992</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.219003</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[115, 97, 99, 148, 134, 132], [115, 101, 99,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9056</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.218660</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[107, 93, 90, 173, 150, 140], [123, 109, 107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9120</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.218316</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[107, 101, 99, 140, 121, 115], [107, 97, 99,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9184</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.217973</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[107, 93, 90, 132, 117, 115], [107, 97, 99, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9248</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.217630</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[82, 61, 58, 140, 125, 115], [90, 77, 74, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9312</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.217286</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[66, 65, 74, 156, 142, 132], [99, 97, 107, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9376</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.216943</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[156, 130, 132, 214, 186, 165], [165, 134, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9440</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.216600</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[99, 109, 115, 123, 113, 99], [99, 113, 123,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9504</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.216256</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[82, 65, 49, 107, 109, 99], [66, 53, 41, 90,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9568</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.215913</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[49, 40, 58, 82, 85, 82], [33, 24, 41, 82, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9632</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.215570</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[74, 85, 99, 66, 69, 82], [74, 85, 99, 16, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9696</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.215226</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[197, 190, 189, 255, 255, 239], [189, 182, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9760</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.214883</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[58, 65, 74, 49, 57, 66], [58, 65, 74, 41, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9824</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.214540</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[156, 158, 165, 255, 255, 247], [123, 125, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9888</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.214196</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[156, 154, 156, 197, 194, 189], [156, 154, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952-9952</th>\n",
       "      <th>2016-09-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.213853</td>\n",
       "      <td>37.119887</td>\n",
       "      <td>[[[132, 138, 140, 58, 69, 82], [206, 206, 206,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102161 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              annotation_date  damage_num  destroyed  \\\n",
       "city   patch_id    date                                                \n",
       "aleppo 10016-10016 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10080 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10144 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10208 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10272 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10336 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10400 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10464 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10528 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10592 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10656 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10720 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10784 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10848 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10912 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-10976 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11040 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11104 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11168 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11232 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11296 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11360 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11424 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11488 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11552 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11616 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11680 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11744 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11808 2016-09-18             NaN         0.0        0.0   \n",
       "       10016-11872 2016-09-18             NaN         0.0        0.0   \n",
       "...                                       ...         ...        ...   \n",
       "       9952-8096   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8160   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8224   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8288   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8352   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8416   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8480   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8544   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8608   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8672   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8736   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8800   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8864   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8928   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-8992   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9056   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9120   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9184   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9248   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9312   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9376   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9440   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9504   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9568   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9632   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9696   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9760   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9824   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9888   2016-09-18             NaN         0.0        0.0   \n",
       "       9952-9952   2016-09-18             NaN         0.0        0.0   \n",
       "\n",
       "                                latitude  longitude  \\\n",
       "city   patch_id    date                               \n",
       "aleppo 10016-10016 2016-09-18  36.213510  37.120230   \n",
       "       10016-10080 2016-09-18  36.213166  37.120230   \n",
       "       10016-10144 2016-09-18  36.212823  37.120230   \n",
       "       10016-10208 2016-09-18  36.212480  37.120230   \n",
       "       10016-10272 2016-09-18  36.212136  37.120230   \n",
       "       10016-10336 2016-09-18  36.211793  37.120230   \n",
       "       10016-10400 2016-09-18  36.211450  37.120230   \n",
       "       10016-10464 2016-09-18  36.211106  37.120230   \n",
       "       10016-10528 2016-09-18  36.210763  37.120230   \n",
       "       10016-10592 2016-09-18  36.210420  37.120230   \n",
       "       10016-10656 2016-09-18  36.210077  37.120230   \n",
       "       10016-10720 2016-09-18  36.209733  37.120230   \n",
       "       10016-10784 2016-09-18  36.209390  37.120230   \n",
       "       10016-10848 2016-09-18  36.209047  37.120230   \n",
       "       10016-10912 2016-09-18  36.208703  37.120230   \n",
       "       10016-10976 2016-09-18  36.208360  37.120230   \n",
       "       10016-11040 2016-09-18  36.208017  37.120230   \n",
       "       10016-11104 2016-09-18  36.207673  37.120230   \n",
       "       10016-11168 2016-09-18  36.207330  37.120230   \n",
       "       10016-11232 2016-09-18  36.206987  37.120230   \n",
       "       10016-11296 2016-09-18  36.206643  37.120230   \n",
       "       10016-11360 2016-09-18  36.206300  37.120230   \n",
       "       10016-11424 2016-09-18  36.205957  37.120230   \n",
       "       10016-11488 2016-09-18  36.205613  37.120230   \n",
       "       10016-11552 2016-09-18  36.205270  37.120230   \n",
       "       10016-11616 2016-09-18  36.204927  37.120230   \n",
       "       10016-11680 2016-09-18  36.204583  37.120230   \n",
       "       10016-11744 2016-09-18  36.204240  37.120230   \n",
       "       10016-11808 2016-09-18  36.203897  37.120230   \n",
       "       10016-11872 2016-09-18  36.203553  37.120230   \n",
       "...                                  ...        ...   \n",
       "       9952-8096   2016-09-18  36.223809  37.119887   \n",
       "       9952-8160   2016-09-18  36.223466  37.119887   \n",
       "       9952-8224   2016-09-18  36.223123  37.119887   \n",
       "       9952-8288   2016-09-18  36.222779  37.119887   \n",
       "       9952-8352   2016-09-18  36.222436  37.119887   \n",
       "       9952-8416   2016-09-18  36.222093  37.119887   \n",
       "       9952-8480   2016-09-18  36.221749  37.119887   \n",
       "       9952-8544   2016-09-18  36.221406  37.119887   \n",
       "       9952-8608   2016-09-18  36.221063  37.119887   \n",
       "       9952-8672   2016-09-18  36.220720  37.119887   \n",
       "       9952-8736   2016-09-18  36.220376  37.119887   \n",
       "       9952-8800   2016-09-18  36.220033  37.119887   \n",
       "       9952-8864   2016-09-18  36.219690  37.119887   \n",
       "       9952-8928   2016-09-18  36.219346  37.119887   \n",
       "       9952-8992   2016-09-18  36.219003  37.119887   \n",
       "       9952-9056   2016-09-18  36.218660  37.119887   \n",
       "       9952-9120   2016-09-18  36.218316  37.119887   \n",
       "       9952-9184   2016-09-18  36.217973  37.119887   \n",
       "       9952-9248   2016-09-18  36.217630  37.119887   \n",
       "       9952-9312   2016-09-18  36.217286  37.119887   \n",
       "       9952-9376   2016-09-18  36.216943  37.119887   \n",
       "       9952-9440   2016-09-18  36.216600  37.119887   \n",
       "       9952-9504   2016-09-18  36.216256  37.119887   \n",
       "       9952-9568   2016-09-18  36.215913  37.119887   \n",
       "       9952-9632   2016-09-18  36.215570  37.119887   \n",
       "       9952-9696   2016-09-18  36.215226  37.119887   \n",
       "       9952-9760   2016-09-18  36.214883  37.119887   \n",
       "       9952-9824   2016-09-18  36.214540  37.119887   \n",
       "       9952-9888   2016-09-18  36.214196  37.119887   \n",
       "       9952-9952   2016-09-18  36.213853  37.119887   \n",
       "\n",
       "                                                                           image  \n",
       "city   patch_id    date                                                           \n",
       "aleppo 10016-10016 2016-09-18  [[[189, 190, 189, 247, 243, 239], [197, 198, 1...  \n",
       "       10016-10080 2016-09-18  [[[173, 178, 181, 239, 239, 239], [173, 174, 1...  \n",
       "       10016-10144 2016-09-18  [[[140, 146, 148, 90, 105, 123], [140, 142, 14...  \n",
       "       10016-10208 2016-09-18  [[[115, 113, 115, 197, 190, 181], [132, 130, 1...  \n",
       "       10016-10272 2016-09-18  [[[156, 154, 148, 66, 53, 41], [148, 142, 140,...  \n",
       "       10016-10336 2016-09-18  [[[156, 170, 181, 255, 255, 255], [148, 162, 1...  \n",
       "       10016-10400 2016-09-18  [[[99, 85, 90, 181, 166, 156], [115, 101, 99, ...  \n",
       "       10016-10464 2016-09-18  [[[115, 89, 90, 123, 97, 90], [115, 85, 82, 90...  \n",
       "       10016-10528 2016-09-18  [[[74, 53, 49, 140, 109, 82], [82, 61, 58, 140...  \n",
       "       10016-10592 2016-09-18  [[[58, 36, 33, 148, 130, 132], [82, 61, 58, 99...  \n",
       "       10016-10656 2016-09-18  [[[197, 194, 197, 123, 121, 123], [197, 194, 1...  \n",
       "       10016-10720 2016-09-18  [[[189, 194, 197, 74, 85, 82], [181, 190, 189,...  \n",
       "       10016-10784 2016-09-18  [[[140, 130, 132, 214, 202, 181], [140, 130, 1...  \n",
       "       10016-10848 2016-09-18  [[[181, 198, 214, 58, 61, 99], [181, 198, 214,...  \n",
       "       10016-10912 2016-09-18  [[[181, 198, 214, 247, 255, 255], [173, 194, 2...  \n",
       "       10016-10976 2016-09-18  [[[66, 85, 82, 107, 89, 99], [74, 93, 90, 74, ...  \n",
       "       10016-11040 2016-09-18  [[[140, 146, 156, 255, 239, 214], [140, 142, 1...  \n",
       "       10016-11104 2016-09-18  [[[82, 93, 107, 82, 85, 99], [74, 89, 107, 82,...  \n",
       "       10016-11168 2016-09-18  [[[206, 215, 222, 255, 255, 247], [214, 219, 2...  \n",
       "       10016-11232 2016-09-18  [[[140, 142, 148, 189, 182, 181], [132, 134, 1...  \n",
       "       10016-11296 2016-09-18  [[[49, 65, 74, 132, 138, 123], [58, 73, 82, 13...  \n",
       "       10016-11360 2016-09-18  [[[115, 113, 123, 189, 166, 156], [123, 125, 1...  \n",
       "       10016-11424 2016-09-18  [[[107, 101, 99, 115, 109, 107], [107, 101, 99...  \n",
       "       10016-11488 2016-09-18  [[[132, 117, 115, 140, 125, 115], [123, 109, 1...  \n",
       "       10016-11552 2016-09-18  [[[115, 101, 99, 140, 134, 123], [115, 97, 99,...  \n",
       "       10016-11616 2016-09-18  [[[115, 101, 99, 206, 174, 165], [115, 101, 99...  \n",
       "       10016-11680 2016-09-18  [[[115, 97, 90, 165, 130, 115], [115, 101, 99,...  \n",
       "       10016-11744 2016-09-18  [[[115, 97, 90, 148, 121, 99], [107, 97, 90, 1...  \n",
       "       10016-11808 2016-09-18  [[[49, 49, 41, 123, 130, 132], [99, 97, 82, 11...  \n",
       "       10016-11872 2016-09-18  [[[197, 194, 189, 255, 231, 214], [206, 202, 2...  \n",
       "...                                                                          ...  \n",
       "       9952-8096   2016-09-18  [[[189, 190, 181, 255, 255, 255], [181, 190, 1...  \n",
       "       9952-8160   2016-09-18  [[[123, 117, 115, 140, 138, 132], [107, 105, 1...  \n",
       "       9952-8224   2016-09-18  [[[58, 73, 74, 222, 215, 206], [58, 69, 66, 24...  \n",
       "       9952-8288   2016-09-18  [[[16, 24, 16, 247, 255, 247], [8, 16, 8, 189,...  \n",
       "       9952-8352   2016-09-18  [[[41, 45, 41, 99, 113, 107], [41, 40, 33, 82,...  \n",
       "       9952-8416   2016-09-18  [[[99, 113, 123, 156, 166, 165], [99, 113, 123...  \n",
       "       9952-8480   2016-09-18  [[[49, 65, 82, 99, 117, 115], [41, 57, 82, 115...  \n",
       "       9952-8544   2016-09-18  [[[173, 166, 165, 189, 190, 189], [173, 170, 1...  \n",
       "       9952-8608   2016-09-18  [[[214, 215, 214, 255, 255, 255], [214, 215, 2...  \n",
       "       9952-8672   2016-09-18  [[[132, 142, 148, 132, 130, 132], [140, 146, 1...  \n",
       "       9952-8736   2016-09-18  [[[8, 16, 8, 115, 130, 148], [33, 40, 41, 41, ...  \n",
       "       9952-8800   2016-09-18  [[[197, 206, 214, 107, 105, 99], [197, 210, 21...  \n",
       "       9952-8864   2016-09-18  [[[107, 93, 90, 156, 130, 123], [115, 97, 90, ...  \n",
       "       9952-8928   2016-09-18  [[[66, 53, 49, 41, 53, 49], [82, 69, 66, 90, 1...  \n",
       "       9952-8992   2016-09-18  [[[115, 97, 99, 148, 134, 132], [115, 101, 99,...  \n",
       "       9952-9056   2016-09-18  [[[107, 93, 90, 173, 150, 140], [123, 109, 107...  \n",
       "       9952-9120   2016-09-18  [[[107, 101, 99, 140, 121, 115], [107, 97, 99,...  \n",
       "       9952-9184   2016-09-18  [[[107, 93, 90, 132, 117, 115], [107, 97, 99, ...  \n",
       "       9952-9248   2016-09-18  [[[82, 61, 58, 140, 125, 115], [90, 77, 74, 14...  \n",
       "       9952-9312   2016-09-18  [[[66, 65, 74, 156, 142, 132], [99, 97, 107, 1...  \n",
       "       9952-9376   2016-09-18  [[[156, 130, 132, 214, 186, 165], [165, 134, 1...  \n",
       "       9952-9440   2016-09-18  [[[99, 109, 115, 123, 113, 99], [99, 113, 123,...  \n",
       "       9952-9504   2016-09-18  [[[82, 65, 49, 107, 109, 99], [66, 53, 41, 90,...  \n",
       "       9952-9568   2016-09-18  [[[49, 40, 58, 82, 85, 82], [33, 24, 41, 82, 8...  \n",
       "       9952-9632   2016-09-18  [[[74, 85, 99, 66, 69, 82], [74, 85, 99, 16, 2...  \n",
       "       9952-9696   2016-09-18  [[[197, 190, 189, 255, 255, 239], [189, 182, 1...  \n",
       "       9952-9760   2016-09-18  [[[58, 65, 74, 49, 57, 66], [58, 65, 74, 41, 4...  \n",
       "       9952-9824   2016-09-18  [[[156, 158, 165, 255, 255, 247], [123, 125, 1...  \n",
       "       9952-9888   2016-09-18  [[[156, 154, 156, 197, 194, 189], [156, 154, 1...  \n",
       "       9952-9952   2016-09-18  [[[132, 138, 140, 58, 69, 82], [206, 206, 206,...  \n",
       "\n",
       "[102161 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_pickle('{}/{}'.format(FEATURES_PATH, features_file_name)).dropna(subset=['destroyed'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-09-18', '2016-10-19'], dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.index.get_level_values('date').unique()\n",
    "# import rasterio\n",
    "# data  = rasterio.open('../data/city_rasters/daraa_2017_02_07_zoom_19.tif')\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102161"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of three custom classes: __RandomSearch__, __CNN__ and __DataStream__. __RandomSearch__ is a class that samples hyperparameters for ML models. As of may 2019, only the space for cnn's has been implemented. __CNN__ is a class that defines a Convolutional Neural Network model and follows the standards of Sklearn and Keras APIs, containing methods called fit, predict, fit_generator, predict_generator and validate_generator. In this case, we make use of the validate_generator method, which takes a generator of data as required by Keras's fit_generator method: each batch yields a tuple of (features, target). We use the __DataStream__ object to create these generators, first by generating the indices with the split_by_path_id method, which follows the standards of Sklearn splitters and then with the get_data_generator_from_index method that turns those indices into data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_units': 256, 'batch_size': 28, 'convolutional_layers': [{'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 32, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 64, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 128, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 256, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 512, 'dropout': 0.17777777777777778, 'activation': 'relu'}], 'epochs': 6, 'layer_type': 'vgg', 'class_weight': 1.15, 'learning_rate': 0.025595479226995357}\n"
     ]
    }
   ],
   "source": [
    "# Modelling\n",
    "sampler = RandomSearch()\n",
    "models = {\n",
    "    CNN:sampler.sample_cnn,\n",
    "    CNNPreTrained: sampler.sample_cnn_pretrained,\n",
    "}\n",
    "Model = random.choice([CNN])\n",
    "sample_func = models[Model]\n",
    "spaces = sample_func(1)\n",
    "# # Do splits\n",
    "# class_proportion = {\n",
    "#     1: 0.3,\n",
    "# }\n",
    "batch_size = spaces[0]['batch_size']\n",
    "test_batch_size = batch_size\n",
    "train_proportion = 0.7\n",
    "data_stream = DataStream(batch_size = batch_size, train_proportion=train_proportion, test_batch_size=test_batch_size)\n",
    "unique_patches = features.index.get_level_values('patch_id').unique().tolist()\n",
    "train_patches = random.sample(unique_patches, round(len(unique_patches)*train_proportion))\n",
    "train_data = features.loc[features.index.get_level_values('patch_id').isin(train_patches)]\n",
    "# if train_data['destroyed'].mean() > class_proportion[1]:\n",
    "#     train_data_upsampled = train_data.copy()\n",
    "# else:\n",
    "#     train_data_upsampled = data_stream._upsample_class_proportion(train_data, class_proportion).sample(frac=1)\n",
    "test_patches = list(set(unique_patches) - set(train_patches))\n",
    "test_data = features.loc[features.index.get_level_values('patch_id').isin(test_patches)]\n",
    "\n",
    "train_indices = data_stream._get_index_generator(train_data, batch_size)\n",
    "test_indices = data_stream._get_index_generator(test_data, test_batch_size)\n",
    "train_generator = data_stream.get_train_data_generator_from_index(\n",
    "    [train_data['image'], train_data['destroyed']], train_indices)\n",
    "test_generator = data_stream.get_train_data_generator_from_index(\n",
    "    [test_data['image'], test_data['destroyed']], test_indices)\n",
    "train_dataset = Dataset.from_generator(lambda: train_generator, (tf.float32, tf.int32))\n",
    "test_dataset = Dataset.from_generator(lambda: test_generator, (tf.float32, tf.int32))\n",
    "num_batches = len(train_indices)\n",
    "num_batches_test = len(test_indices)\n",
    "print(spaces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now validating:\n",
      "\n",
      "{'dense_units': 256, 'batch_size': 28, 'convolutional_layers': [{'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 32, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 64, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 128, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 256, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 512, 'dropout': 0.17777777777777778, 'activation': 'relu'}], 'epochs': 6, 'layer_type': 'vgg', 'class_weight': 1.15, 'learning_rate': 0.025595479226995357}\n",
      "Epoch 1/6\n",
      " 6/21 [=======>......................] - ETA: 34:20 - loss: 6.2176 - accuracy: 0.6229 - recall_positives: 0.5006 - recall_negatives: 0.6534 - precision_positives: 0.2780 - precision_negatives: 0.8403 - negatives: 23.0000 - positives: 5.6500 - true_positives: 2.8278 - true_negatives: 15.0278 - false_positives: 7.9722 - false_negatives: 2.8222"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0218ad294acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                           **space)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Jordi_MyPassport/building-damage/damage/models/base.py\u001b[0m in \u001b[0;36mvalidate_generator\u001b[0;34m(self, train_generator, test_generator, validation_steps, epochs, steps_per_epoch, class_weight, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         model_fit = self.model.fit_generator(train_generator, validation_data=test_generator,\n\u001b[1;32m     28\u001b[0m                                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                              steps_per_epoch=steps_per_epoch, class_weight=class_weight)\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Validate\n",
    "for space in spaces:\n",
    "    print('Now validating:\\n')\n",
    "    print(space)\n",
    "    try:\n",
    "        model = Model(**space)\n",
    "        losses = model.validate_generator(train_dataset, test_dataset,\n",
    "                                          steps_per_epoch=num_batches,\n",
    "                                          validation_steps=num_batches_test,\n",
    "                                          **space)\n",
    "    except Exception as e:\n",
    "        losses = {'log': str(e)}\n",
    "\n",
    "    losses['model'] = str(Model)\n",
    "    losses['space'] = space\n",
    "    losses['features'] = features_file_name\n",
    "    losses['num_batches_train'] = num_batches\n",
    "    losses['num_batches_test'] = num_batches_test\n",
    "    identifier = round(time())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/experiment_{}.json'.format(RESULTS_PATH, identifier), 'w') as f:\n",
    "        json.dump(str(losses), f)\n",
    "if 'val_recall_positives' in losses.keys():\n",
    "    if losses['val_recall_positives'][-1] > 0.4 and losses['val_precision_positives'][-1] > 0.1:\n",
    "        model.save('../logs/models/model_{}.h5'.format(identifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [6.438632979860815,\n",
       "  6.363179270864149,\n",
       "  6.035386882427432,\n",
       "  6.399254071322653,\n",
       "  6.310763664787279,\n",
       "  6.308132805635514,\n",
       "  6.247735060430845,\n",
       "  6.187669580036104,\n",
       "  6.274610529668155,\n",
       "  6.135942042181701,\n",
       "  6.164134275072002,\n",
       "  6.155083573418517],\n",
       " 'accuracy': [0.5628227,\n",
       "  0.5748709,\n",
       "  0.59380376,\n",
       "  0.5748709,\n",
       "  0.58003443,\n",
       "  0.5697074,\n",
       "  0.57831323,\n",
       "  0.5834768,\n",
       "  0.5886403,\n",
       "  0.5834768,\n",
       "  0.5869191,\n",
       "  0.58003443],\n",
       " 'recall_positives': [0.49122804,\n",
       "  0.47368416,\n",
       "  0.5,\n",
       "  0.48245612,\n",
       "  0.47368416,\n",
       "  0.49122804,\n",
       "  0.47368416,\n",
       "  0.46491227,\n",
       "  0.48245612,\n",
       "  0.4649122,\n",
       "  0.47368422,\n",
       "  0.44736847],\n",
       " 'recall_negatives': [0.58,\n",
       "  0.59938586,\n",
       "  0.6164035,\n",
       "  0.59719294,\n",
       "  0.6059649,\n",
       "  0.588772,\n",
       "  0.6035965,\n",
       "  0.6120176,\n",
       "  0.6142983,\n",
       "  0.612193,\n",
       "  0.6142983,\n",
       "  0.6120176],\n",
       " 'precision_positives': [0.22428645,\n",
       "  0.22784775,\n",
       "  0.24540545,\n",
       "  0.22996561,\n",
       "  0.22892281,\n",
       "  0.23117366,\n",
       "  0.23320274,\n",
       "  0.23414735,\n",
       "  0.24406579,\n",
       "  0.23490594,\n",
       "  0.23788176,\n",
       "  0.22662668],\n",
       " 'precision_negatives': [0.8229152,\n",
       "  0.82129604,\n",
       "  0.83314306,\n",
       "  0.8235008,\n",
       "  0.82428414,\n",
       "  0.8235182,\n",
       "  0.82085866,\n",
       "  0.81994635,\n",
       "  0.82450444,\n",
       "  0.81981444,\n",
       "  0.82354075,\n",
       "  0.8161918],\n",
       " 'negatives': [24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947],\n",
       " 'positives': [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],\n",
       " 'true_positives': [2.9473684,\n",
       "  2.8421052,\n",
       "  3.0,\n",
       "  2.8947368,\n",
       "  2.8421052,\n",
       "  2.9473684,\n",
       "  2.8421052,\n",
       "  2.7894738,\n",
       "  2.8947368,\n",
       "  2.7894738,\n",
       "  2.8421052,\n",
       "  2.6842105],\n",
       " 'true_negatives': [14.263158,\n",
       "  14.736842,\n",
       "  15.157895,\n",
       "  14.684211,\n",
       "  14.894737,\n",
       "  14.473684,\n",
       "  14.842105,\n",
       "  15.052631,\n",
       "  15.105263,\n",
       "  15.052631,\n",
       "  15.105263,\n",
       "  15.052631],\n",
       " 'false_positives': [10.315789,\n",
       "  9.842105,\n",
       "  9.421053,\n",
       "  9.894737,\n",
       "  9.684211,\n",
       "  10.105263,\n",
       "  9.736842,\n",
       "  9.526316,\n",
       "  9.473684,\n",
       "  9.526316,\n",
       "  9.473684,\n",
       "  9.526316],\n",
       " 'false_negatives': [3.0526316,\n",
       "  3.1578948,\n",
       "  3.0,\n",
       "  3.1052632,\n",
       "  3.1578948,\n",
       "  3.0526316,\n",
       "  3.1578948,\n",
       "  3.2105262,\n",
       "  3.1052632,\n",
       "  3.2105262,\n",
       "  3.1578948,\n",
       "  3.3157895],\n",
       " 'val_loss': [2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.2916147973802357,\n",
       "  2.4155607488420276,\n",
       "  2.7870024310217962,\n",
       "  2.8498560322655573],\n",
       " 'val_accuracy': [0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.8514056,\n",
       "  0.8433735,\n",
       "  0.81526107,\n",
       "  0.81124496],\n",
       " 'val_recall_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.055555556],\n",
       " 'val_recall_negatives': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.99537045,\n",
       "  0.9859099,\n",
       "  0.95330113,\n",
       "  0.9392109],\n",
       " 'val_precision_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16666666],\n",
       " 'val_precision_negatives': [0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.85479134,\n",
       "  0.8535703,\n",
       "  0.84907705,\n",
       "  0.8542948],\n",
       " 'val_negatives': [23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666],\n",
       " 'val_positives': [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],\n",
       " 'val_true_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22222222],\n",
       " 'val_true_negatives': [23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.555555,\n",
       "  23.333334,\n",
       "  22.555555,\n",
       "  22.222221],\n",
       " 'val_false_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.11111111,\n",
       "  0.33333334,\n",
       "  1.1111112,\n",
       "  1.4444444],\n",
       " 'val_false_negatives': [4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  3.7777777],\n",
       " 'model': \"<class 'damage.models.cnn.CNN'>\",\n",
       " 'space': {'dense_units': 128,\n",
       "  'batch_size': 31,\n",
       "  'convolutional_layers': [{'kernel_size': [5, 5],\n",
       "    'pool_size': [4, 4],\n",
       "    'filters': 32,\n",
       "    'dropout': 0.17777777777777778,\n",
       "    'activation': 'relu'},\n",
       "   {'kernel_size': [5, 5],\n",
       "    'pool_size': [4, 4],\n",
       "    'filters': 64,\n",
       "    'dropout': 0.17777777777777778,\n",
       "    'activation': 'relu'}],\n",
       "  'epochs': 12,\n",
       "  'layer_type': 'vgg',\n",
       "  'class_weight': 1.15,\n",
       "  'learning_rate': 0.21209508879201905},\n",
       " 'features': 'example_daraa.p',\n",
       " 'num_batches_train': 19,\n",
       " 'num_batches_test': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
