{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Validating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we can see how to validate models. Note that it requires to have run the TUTORIAL_00 notebook first so we precompute the features that will be used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "from damage.data import DataStream\n",
    "from damage.models import CNN, RandomSearch, CNNPreTrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "RESULTS_PATH = '../logs/experiments'\n",
    "FEATURES_PATH = '../logs/features'\n",
    "features_file_name = 'example_daraa.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>damage_num</th>\n",
       "      <th>destroyed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">daraa</th>\n",
       "      <th>10080-8224</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.616861</td>\n",
       "      <td>36.122191</td>\n",
       "      <td>[[[99, 85, 74, 90, 65, 58], [99, 81, 74, 90, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208-8288</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.616517</td>\n",
       "      <td>36.122878</td>\n",
       "      <td>[[[123, 125, 123, 90, 61, 58], [107, 113, 115,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272-4768</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.635400</td>\n",
       "      <td>36.123221</td>\n",
       "      <td>[[[99, 73, 66, 41, 40, 41], [99, 73, 66, 41, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336-7904</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.618577</td>\n",
       "      <td>36.123565</td>\n",
       "      <td>[[[181, 190, 197, 132, 89, 74], [181, 186, 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400-8160</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.617204</td>\n",
       "      <td>36.123908</td>\n",
       "      <td>[[[99, 97, 99, 49, 45, 41], [82, 85, 82, 49, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            annotation_date  damage_num  destroyed   latitude  \\\n",
       "city  patch_id   date                                                           \n",
       "daraa 10080-8224 2017-02-07      2016-04-19         2.0        0.0  32.616861   \n",
       "      10208-8288 2017-02-07      2016-04-19         1.0        0.0  32.616517   \n",
       "      10272-4768 2017-02-07      2016-04-19         1.0        0.0  32.635400   \n",
       "      10336-7904 2017-02-07      2016-04-19         3.0        1.0  32.618577   \n",
       "      10400-8160 2017-02-07      2016-04-19         2.0        0.0  32.617204   \n",
       "\n",
       "                             longitude  \\\n",
       "city  patch_id   date                    \n",
       "daraa 10080-8224 2017-02-07  36.122191   \n",
       "      10208-8288 2017-02-07  36.122878   \n",
       "      10272-4768 2017-02-07  36.123221   \n",
       "      10336-7904 2017-02-07  36.123565   \n",
       "      10400-8160 2017-02-07  36.123908   \n",
       "\n",
       "                                                                         image  \n",
       "city  patch_id   date                                                           \n",
       "daraa 10080-8224 2017-02-07  [[[99, 85, 74, 90, 65, 58], [99, 81, 74, 90, 6...  \n",
       "      10208-8288 2017-02-07  [[[123, 125, 123, 90, 61, 58], [107, 113, 115,...  \n",
       "      10272-4768 2017-02-07  [[[99, 73, 66, 41, 40, 41], [99, 73, 66, 41, 4...  \n",
       "      10336-7904 2017-02-07  [[[181, 190, 197, 132, 89, 74], [181, 186, 189...  \n",
       "      10400-8160 2017-02-07  [[[99, 97, 99, 49, 45, 41], [82, 85, 82, 49, 4...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_pickle('{}/{}'.format(FEATURES_PATH, features_file_name)).dropna(subset=['destroyed'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "830"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of three custom classes: __RandomSearch__, __CNN__ and __DataStream__. __RandomSearch__ is a class that samples hyperparameters for ML models. As of may 2019, only the space for cnn's has been implemented. __CNN__ is a class that defines a Convolutional Neural Network model and follows the standards of Sklearn and Keras APIs, containing methods called fit, predict, fit_generator, predict_generator and validate_generator. In this case, we make use of the validate_generator method, which takes a generator of data as required by Keras's fit_generator method: each batch yields a tuple of (features, target). We use the __DataStream__ object to create these generators, first by generating the indices with the split_by_path_id method, which follows the standards of Sklearn splitters and then with the get_data_generator_from_index method that turns those indices into data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_units': 128, 'batch_size': 31, 'convolutional_layers': [{'kernel_size': [5, 5], 'pool_size': [4, 4], 'filters': 32, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [5, 5], 'pool_size': [4, 4], 'filters': 64, 'dropout': 0.17777777777777778, 'activation': 'relu'}], 'epochs': 12, 'layer_type': 'vgg', 'class_weight': 1.15, 'learning_rate': 0.21209508879201905}\n"
     ]
    }
   ],
   "source": [
    "# Modelling\n",
    "sampler = RandomSearch()\n",
    "models = {\n",
    "    CNN:sampler.sample_cnn,\n",
    "    CNNPreTrained: sampler.sample_cnn_pretrained,\n",
    "}\n",
    "Model = random.choice([CNN])\n",
    "sample_func = models[Model]\n",
    "spaces = sample_func(1)\n",
    "# # Do splits\n",
    "# class_proportion = {\n",
    "#     1: 0.3,\n",
    "# }\n",
    "batch_size = spaces[0]['batch_size']\n",
    "test_batch_size = batch_size\n",
    "train_proportion = 0.7\n",
    "data_stream = DataStream(batch_size = batch_size, train_proportion=train_proportion, test_batch_size=test_batch_size)\n",
    "unique_patches = features.index.get_level_values('patch_id').unique().tolist()\n",
    "train_patches = random.sample(unique_patches, round(len(unique_patches)*train_proportion))\n",
    "train_data = features.loc[features.index.get_level_values('patch_id').isin(train_patches)]\n",
    "# if train_data['destroyed'].mean() > class_proportion[1]:\n",
    "#     train_data_upsampled = train_data.copy()\n",
    "# else:\n",
    "#     train_data_upsampled = data_stream._upsample_class_proportion(train_data, class_proportion).sample(frac=1)\n",
    "test_patches = list(set(unique_patches) - set(train_patches))\n",
    "test_data = features.loc[features.index.get_level_values('patch_id').isin(test_patches)]\n",
    "\n",
    "train_indices = data_stream._get_index_generator(train_data, batch_size)\n",
    "test_indices = data_stream._get_index_generator(test_data, test_batch_size)\n",
    "train_generator = data_stream.get_train_data_generator_from_index(\n",
    "    [train_data['image'], train_data['destroyed']], train_indices)\n",
    "test_generator = data_stream.get_train_data_generator_from_index(\n",
    "    [test_data['image'], test_data['destroyed']], test_indices)\n",
    "train_dataset = Dataset.from_generator(lambda: train_generator, (tf.float32, tf.int32))\n",
    "test_dataset = Dataset.from_generator(lambda: test_generator, (tf.float32, tf.int32))\n",
    "num_batches = len(train_indices)\n",
    "num_batches_test = len(test_indices)\n",
    "print(spaces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now validating:\n",
      "\n",
      "{'dense_units': 128, 'batch_size': 31, 'convolutional_layers': [{'kernel_size': [5, 5], 'pool_size': [4, 4], 'filters': 32, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [5, 5], 'pool_size': [4, 4], 'filters': 64, 'dropout': 0.17777777777777778, 'activation': 'relu'}], 'epochs': 12, 'layer_type': 'vgg', 'class_weight': 1.15, 'learning_rate': 0.21209508879201905}\n",
      "Epoch 1/12\n",
      "19/19 [==============================] - 61s 3s/step - loss: 6.4445 - accuracy: 0.5814 - recall_positives: 0.5248 - recall_negatives: 0.5950 - precision_positives: 0.2411 - precision_negatives: 0.8381 - negatives: 24.8693 - positives: 6.0000 - true_positives: 3.1486 - true_negatives: 14.8010 - false_positives: 10.0683 - false_negatives: 2.8514 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 2/12\n",
      "19/19 [==============================] - 63s 3s/step - loss: 6.3682 - accuracy: 0.5823 - recall_positives: 0.5450 - recall_negatives: 0.5913 - precision_positives: 0.2451 - precision_negatives: 0.8429 - negatives: 24.8693 - positives: 6.0000 - true_positives: 3.2699 - true_negatives: 14.7061 - false_positives: 10.1632 - false_negatives: 2.7301 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 3/12\n",
      "19/19 [==============================] - 56s 3s/step - loss: 6.0396 - accuracy: 0.6036 - recall_positives: 0.5266 - recall_negatives: 0.6220 - precision_positives: 0.2524 - precision_negatives: 0.8451 - negatives: 24.8693 - positives: 6.0000 - true_positives: 3.1597 - true_negatives: 15.4724 - false_positives: 9.3969 - false_negatives: 2.8403 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 4/12\n",
      "19/19 [==============================] - 57s 3s/step - loss: 6.4024 - accuracy: 0.5727 - recall_positives: 0.4824 - recall_negatives: 0.5943 - precision_positives: 0.2255 - precision_negatives: 0.8253 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.8945 - true_negatives: 14.7822 - false_positives: 10.0871 - false_negatives: 3.1055 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 5/12\n",
      "19/19 [==============================] - 55s 3s/step - loss: 6.3137 - accuracy: 0.5753 - recall_positives: 0.4687 - recall_negatives: 0.6010 - precision_positives: 0.2220 - precision_negatives: 0.8241 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.8122 - true_negatives: 14.9466 - false_positives: 9.9226 - false_negatives: 3.1878 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 6/12\n",
      "19/19 [==============================] - 54s 3s/step - loss: 6.3108 - accuracy: 0.5612 - recall_positives: 0.4842 - recall_negatives: 0.5797 - precision_positives: 0.2211 - precision_negatives: 0.8219 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.9055 - true_negatives: 14.4165 - false_positives: 10.4528 - false_negatives: 3.0945 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 7/12\n",
      "19/19 [==============================] - 56s 3s/step - loss: 6.2519 - accuracy: 0.5770 - recall_positives: 0.4770 - recall_negatives: 0.6011 - precision_positives: 0.2322 - precision_negatives: 0.8222 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.8620 - true_negatives: 14.9501 - false_positives: 9.9191 - false_negatives: 3.1380 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 8/12\n",
      "19/19 [==============================] - 55s 3s/step - loss: 6.1933 - accuracy: 0.5834 - recall_positives: 0.4641 - recall_negatives: 0.6121 - precision_positives: 0.2312 - precision_negatives: 0.8217 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.7845 - true_negatives: 15.2242 - false_positives: 9.6451 - false_negatives: 3.2155 - val_loss: 2.2308 - val_accuracy: 0.8554 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 1.0000 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8554 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.6667 - val_false_positives: 0.0000e+00 - val_false_negatives: 4.0000\n",
      "Epoch 9/12\n",
      "19/19 [==============================] - 55s 3s/step - loss: 6.2788 - accuracy: 0.5837 - recall_positives: 0.4824 - recall_negatives: 0.6081 - precision_positives: 0.2376 - precision_negatives: 0.8249 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.8945 - true_negatives: 15.1231 - false_positives: 9.7462 - false_negatives: 3.1055 - val_loss: 2.2916 - val_accuracy: 0.8514 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 0.9954 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8548 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.5556 - val_false_positives: 0.1111 - val_false_negatives: 4.0000\n",
      "Epoch 10/12\n",
      "19/19 [==============================] - 55s 3s/step - loss: 6.1397 - accuracy: 0.5826 - recall_positives: 0.4737 - recall_negatives: 0.6088 - precision_positives: 0.2331 - precision_negatives: 0.8235 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.8423 - true_negatives: 15.1416 - false_positives: 9.7277 - false_negatives: 3.1577 - val_loss: 2.4156 - val_accuracy: 0.8434 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 0.9859 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8536 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 23.3333 - val_false_positives: 0.3333 - val_false_negatives: 4.0000\n",
      "Epoch 11/12\n",
      "19/19 [==============================] - 55s 3s/step - loss: 6.1694 - accuracy: 0.5870 - recall_positives: 0.4795 - recall_negatives: 0.6128 - precision_positives: 0.2355 - precision_negatives: 0.8273 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.8771 - true_negatives: 15.2412 - false_positives: 9.6281 - false_negatives: 3.1229 - val_loss: 2.7870 - val_accuracy: 0.8153 - val_recall_positives: 0.0000e+00 - val_recall_negatives: 0.9533 - val_precision_positives: 0.0000e+00 - val_precision_negatives: 0.8491 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.0000e+00 - val_true_negatives: 22.5556 - val_false_positives: 1.1111 - val_false_negatives: 4.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/12\n",
      "19/19 [==============================] - 55s 3s/step - loss: 6.1604 - accuracy: 0.5851 - recall_positives: 0.4565 - recall_negatives: 0.6160 - precision_positives: 0.2285 - precision_negatives: 0.8219 - negatives: 24.8693 - positives: 6.0000 - true_positives: 2.7387 - true_negatives: 15.3219 - false_positives: 9.5473 - false_negatives: 3.2613 - val_loss: 2.8499 - val_accuracy: 0.8112 - val_recall_positives: 0.0556 - val_recall_negatives: 0.9392 - val_precision_positives: 0.1667 - val_precision_negatives: 0.8543 - val_negatives: 23.6667 - val_positives: 4.0000 - val_true_positives: 0.2222 - val_true_negatives: 22.2222 - val_false_positives: 1.4444 - val_false_negatives: 3.7778\n"
     ]
    }
   ],
   "source": [
    "#Validate\n",
    "for space in spaces:\n",
    "    print('Now validating:\\n')\n",
    "    print(space)\n",
    "    try:\n",
    "        model = Model(**space)\n",
    "        losses = model.validate_generator(train_dataset, test_dataset,\n",
    "                                          steps_per_epoch=num_batches,\n",
    "                                          validation_steps=num_batches_test,\n",
    "                                          **space)\n",
    "    except Exception as e:\n",
    "        losses = {'log': str(e)}\n",
    "\n",
    "    losses['model'] = str(Model)\n",
    "    losses['space'] = space\n",
    "    losses['features'] = features_file_name\n",
    "    losses['num_batches_train'] = num_batches\n",
    "    losses['num_batches_test'] = num_batches_test\n",
    "    identifier = round(time())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/experiment_{}.json'.format(RESULTS_PATH, identifier), 'w') as f:\n",
    "        json.dump(str(losses), f)\n",
    "if 'val_recall_positives' in losses.keys():\n",
    "    if losses['val_recall_positives'][-1] > 0.4 and losses['val_precision_positives'][-1] > 0.1:\n",
    "        model.save('../logs/models/model_{}.h5'.format(identifier))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
