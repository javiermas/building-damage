{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Validating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we can see how to validate models. Note that it requires to have run the TUTORIAL_00 notebook first so we precompute the features that will be used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.errors import ResourceExhaustedError\n",
    "\n",
    "from damage.data import DataStream\n",
    "from damage.models import CNN, RandomSearch, CNNPreTrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "RESULTS_PATH = '../logs/experiments'\n",
    "FEATURES_PATH = '../logs/features'\n",
    "features_file_name = 'example.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>destroyed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">raqqa</th>\n",
       "      <th>10016-2208</th>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.965631</td>\n",
       "      <td>38.987906</td>\n",
       "      <td>[[[115, 121, 123, 156, 142, 132], [115, 121, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-2272</th>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.965287</td>\n",
       "      <td>38.987906</td>\n",
       "      <td>[[[41, 40, 74, 66, 53, 66], [41, 40, 66, 66, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-2336</th>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.964944</td>\n",
       "      <td>38.987906</td>\n",
       "      <td>[[[74, 81, 90, 82, 97, 99], [99, 105, 115, 107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-2400</th>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.964601</td>\n",
       "      <td>38.987906</td>\n",
       "      <td>[[[74, 77, 99, 197, 194, 197], [74, 85, 99, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016-2464</th>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.964257</td>\n",
       "      <td>38.987906</td>\n",
       "      <td>[[[165, 166, 181, 247, 247, 255], [165, 170, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            annotation_date  destroyed   latitude  longitude  \\\n",
       "city  patch_id   date                                                          \n",
       "raqqa 10016-2208 2015-02-02             NaT        0.0  35.965631  38.987906   \n",
       "      10016-2272 2015-02-02             NaT        0.0  35.965287  38.987906   \n",
       "      10016-2336 2015-02-02             NaT        0.0  35.964944  38.987906   \n",
       "      10016-2400 2015-02-02             NaT        0.0  35.964601  38.987906   \n",
       "      10016-2464 2015-02-02             NaT        0.0  35.964257  38.987906   \n",
       "\n",
       "                                                                         image  \n",
       "city  patch_id   date                                                           \n",
       "raqqa 10016-2208 2015-02-02  [[[115, 121, 123, 156, 142, 132], [115, 121, 1...  \n",
       "      10016-2272 2015-02-02  [[[41, 40, 74, 66, 53, 66], [41, 40, 66, 66, 5...  \n",
       "      10016-2336 2015-02-02  [[[74, 81, 90, 82, 97, 99], [99, 105, 115, 107...  \n",
       "      10016-2400 2015-02-02  [[[74, 77, 99, 197, 194, 197], [74, 85, 99, 18...  \n",
       "      10016-2464 2015-02-02  [[[165, 166, 181, 247, 247, 255], [165, 170, 1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_pickle('{}/{}'.format(FEATURES_PATH, features_file_name)).dropna(subset=['destroyed', 'image'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-02-02'], dtype='datetime64[ns]', name='date', freq=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.index.get_level_values('date').unique()\n",
    "# import rasterio\n",
    "# data  = rasterio.open('../data/city_rasters/daraa_2017_02_07_zoom_19.tif')\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22091"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of three custom classes: __RandomSearch__, __CNN__ and __DataStream__. __RandomSearch__ is a class that samples hyperparameters for ML models. As of may 2019, only the space for cnn's has been implemented. __CNN__ is a class that defines a Convolutional Neural Network model and follows the standards of Sklearn and Keras APIs, containing methods called fit, predict, fit_generator, predict_generator and validate_generator. In this case, we make use of the validate_generator method, which takes a generator of data as required by Keras's fit_generator method: each batch yields a tuple of (features, target). We use the __DataStream__ object to create these generators, first by generating the indices with the split_by_path_id method, which follows the standards of Sklearn splitters and then with the get_data_generator_from_index method that turns those indices into data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_train_data_generator_from_index() missing 2 required positional arguments: 'augment_flip' and 'augment_brightness'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4835e3142372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m test_generator = data_stream.get_train_data_generator_from_index(\n\u001b[0;32m---> 41\u001b[0;31m     [test_data['image'], test_data['destroyed']], test_indices)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_train_data_generator_from_index() missing 2 required positional arguments: 'augment_flip' and 'augment_brightness'"
     ]
    }
   ],
   "source": [
    "# Modelling\n",
    "sampler = RandomSearch()\n",
    "models = {\n",
    "    CNN:sampler.sample_cnn,\n",
    "    CNNPreTrained: sampler.sample_cnn_pretrained,\n",
    "}\n",
    "Model = random.choice([CNN])\n",
    "sample_func = models[Model]\n",
    "spaces = sample_func(1)\n",
    "# # Do splits\n",
    "# class_proportion = {\n",
    "#     1: 0.3,\n",
    "# }\n",
    "batch_size = spaces[0]['batch_size']\n",
    "test_batch_size = batch_size\n",
    "train_proportion = 0.7\n",
    "data_stream = DataStream(\n",
    "    batch_size=batch_size,\n",
    "    train_proportion=train_proportion,\n",
    "    test_batch_size=test_batch_size\n",
    ")\n",
    "unique_patches = features.index.get_level_values('patch_id').unique().tolist()\n",
    "train_patches = random.sample(unique_patches, round(len(unique_patches)*train_proportion))\n",
    "train_data = features.loc[features.index.get_level_values('patch_id').isin(train_patches)]\n",
    "# if train_data['destroyed'].mean() > class_proportion[1]:\n",
    "#     train_data_upsampled = train_data.copy()\n",
    "# else:\n",
    "#     train_data_upsampled = data_stream._upsample_class_proportion(train_data, class_proportion).sample(frac=1)\n",
    "test_patches = list(set(unique_patches) - set(train_patches))\n",
    "test_data = features.loc[features.index.get_level_values('patch_id').isin(test_patches)]\n",
    "\n",
    "train_indices = data_stream._get_index_generator(train_data, batch_size)\n",
    "test_indices = data_stream._get_index_generator(test_data, test_batch_size)\n",
    "train_generator = data_stream.get_train_data_generator_from_index(\n",
    "    [train_data['image'], train_data['destroyed']],\n",
    "    train_indices,\n",
    "    augment_flip=False,\n",
    "    augment_brightness=False,\n",
    ")\n",
    "test_generator = data_stream.get_train_data_generator_from_index(\n",
    "    [test_data['image'], test_data['destroyed']], test_indices)\n",
    "train_dataset = Dataset.from_generator(lambda: train_generator, (tf.float32, tf.int32))\n",
    "test_dataset = Dataset.from_generator(lambda: test_generator, (tf.float32, tf.int32))\n",
    "num_batches = len(train_indices)\n",
    "num_batches_test = len(test_indices)\n",
    "print(spaces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now validating:\n",
      "\n",
      "{'dense_units': 256, 'batch_size': 28, 'convolutional_layers': [{'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 32, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 64, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 128, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 256, 'dropout': 0.17777777777777778, 'activation': 'relu'}, {'kernel_size': [9, 9], 'pool_size': [8, 8], 'filters': 512, 'dropout': 0.17777777777777778, 'activation': 'relu'}], 'epochs': 6, 'layer_type': 'vgg', 'class_weight': 1.15, 'learning_rate': 0.025595479226995357}\n",
      "Epoch 1/6\n",
      " 6/21 [=======>......................] - ETA: 34:20 - loss: 6.2176 - accuracy: 0.6229 - recall_positives: 0.5006 - recall_negatives: 0.6534 - precision_positives: 0.2780 - precision_negatives: 0.8403 - negatives: 23.0000 - positives: 5.6500 - true_positives: 2.8278 - true_negatives: 15.0278 - false_positives: 7.9722 - false_negatives: 2.8222"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0218ad294acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_batches_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                           **space)\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Jordi_MyPassport/building-damage/damage/models/base.py\u001b[0m in \u001b[0;36mvalidate_generator\u001b[0;34m(self, train_generator, test_generator, validation_steps, epochs, steps_per_epoch, class_weight, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         model_fit = self.model.fit_generator(train_generator, validation_data=test_generator,\n\u001b[1;32m     28\u001b[0m                                              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                              steps_per_epoch=steps_per_epoch, class_weight=class_weight)\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Validate\n",
    "for space in spaces:\n",
    "    print('Now validating:\\n')\n",
    "    print(space)\n",
    "    try:\n",
    "        model = Model(**space)\n",
    "        losses = model.validate_generator(train_dataset, test_dataset,\n",
    "                                          steps_per_epoch=num_batches,\n",
    "                                          validation_steps=num_batches_test,\n",
    "                                          **space)\n",
    "    except Exception as e:\n",
    "        losses = {'log': str(e)}\n",
    "\n",
    "    losses['model'] = str(Model)\n",
    "    losses['space'] = space\n",
    "    losses['features'] = features_file_name\n",
    "    losses['num_batches_train'] = num_batches\n",
    "    losses['num_batches_test'] = num_batches_test\n",
    "    identifier = round(time())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}/experiment_{}.json'.format(RESULTS_PATH, identifier), 'w') as f:\n",
    "        json.dump(str(losses), f)\n",
    "if 'val_recall_positives' in losses.keys():\n",
    "    if losses['val_recall_positives'][-1] > 0.4 and losses['val_precision_positives'][-1] > 0.1:\n",
    "        model.save('../logs/models/model_{}.h5'.format(identifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [6.438632979860815,\n",
       "  6.363179270864149,\n",
       "  6.035386882427432,\n",
       "  6.399254071322653,\n",
       "  6.310763664787279,\n",
       "  6.308132805635514,\n",
       "  6.247735060430845,\n",
       "  6.187669580036104,\n",
       "  6.274610529668155,\n",
       "  6.135942042181701,\n",
       "  6.164134275072002,\n",
       "  6.155083573418517],\n",
       " 'accuracy': [0.5628227,\n",
       "  0.5748709,\n",
       "  0.59380376,\n",
       "  0.5748709,\n",
       "  0.58003443,\n",
       "  0.5697074,\n",
       "  0.57831323,\n",
       "  0.5834768,\n",
       "  0.5886403,\n",
       "  0.5834768,\n",
       "  0.5869191,\n",
       "  0.58003443],\n",
       " 'recall_positives': [0.49122804,\n",
       "  0.47368416,\n",
       "  0.5,\n",
       "  0.48245612,\n",
       "  0.47368416,\n",
       "  0.49122804,\n",
       "  0.47368416,\n",
       "  0.46491227,\n",
       "  0.48245612,\n",
       "  0.4649122,\n",
       "  0.47368422,\n",
       "  0.44736847],\n",
       " 'recall_negatives': [0.58,\n",
       "  0.59938586,\n",
       "  0.6164035,\n",
       "  0.59719294,\n",
       "  0.6059649,\n",
       "  0.588772,\n",
       "  0.6035965,\n",
       "  0.6120176,\n",
       "  0.6142983,\n",
       "  0.612193,\n",
       "  0.6142983,\n",
       "  0.6120176],\n",
       " 'precision_positives': [0.22428645,\n",
       "  0.22784775,\n",
       "  0.24540545,\n",
       "  0.22996561,\n",
       "  0.22892281,\n",
       "  0.23117366,\n",
       "  0.23320274,\n",
       "  0.23414735,\n",
       "  0.24406579,\n",
       "  0.23490594,\n",
       "  0.23788176,\n",
       "  0.22662668],\n",
       " 'precision_negatives': [0.8229152,\n",
       "  0.82129604,\n",
       "  0.83314306,\n",
       "  0.8235008,\n",
       "  0.82428414,\n",
       "  0.8235182,\n",
       "  0.82085866,\n",
       "  0.81994635,\n",
       "  0.82450444,\n",
       "  0.81981444,\n",
       "  0.82354075,\n",
       "  0.8161918],\n",
       " 'negatives': [24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947,\n",
       "  24.578947],\n",
       " 'positives': [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0],\n",
       " 'true_positives': [2.9473684,\n",
       "  2.8421052,\n",
       "  3.0,\n",
       "  2.8947368,\n",
       "  2.8421052,\n",
       "  2.9473684,\n",
       "  2.8421052,\n",
       "  2.7894738,\n",
       "  2.8947368,\n",
       "  2.7894738,\n",
       "  2.8421052,\n",
       "  2.6842105],\n",
       " 'true_negatives': [14.263158,\n",
       "  14.736842,\n",
       "  15.157895,\n",
       "  14.684211,\n",
       "  14.894737,\n",
       "  14.473684,\n",
       "  14.842105,\n",
       "  15.052631,\n",
       "  15.105263,\n",
       "  15.052631,\n",
       "  15.105263,\n",
       "  15.052631],\n",
       " 'false_positives': [10.315789,\n",
       "  9.842105,\n",
       "  9.421053,\n",
       "  9.894737,\n",
       "  9.684211,\n",
       "  10.105263,\n",
       "  9.736842,\n",
       "  9.526316,\n",
       "  9.473684,\n",
       "  9.526316,\n",
       "  9.473684,\n",
       "  9.526316],\n",
       " 'false_negatives': [3.0526316,\n",
       "  3.1578948,\n",
       "  3.0,\n",
       "  3.1052632,\n",
       "  3.1578948,\n",
       "  3.0526316,\n",
       "  3.1578948,\n",
       "  3.2105262,\n",
       "  3.1052632,\n",
       "  3.2105262,\n",
       "  3.1578948,\n",
       "  3.3157895],\n",
       " 'val_loss': [2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.23076860109965,\n",
       "  2.2916147973802357,\n",
       "  2.4155607488420276,\n",
       "  2.7870024310217962,\n",
       "  2.8498560322655573],\n",
       " 'val_accuracy': [0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.85542166,\n",
       "  0.8514056,\n",
       "  0.8433735,\n",
       "  0.81526107,\n",
       "  0.81124496],\n",
       " 'val_recall_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.055555556],\n",
       " 'val_recall_negatives': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.99537045,\n",
       "  0.9859099,\n",
       "  0.95330113,\n",
       "  0.9392109],\n",
       " 'val_precision_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16666666],\n",
       " 'val_precision_negatives': [0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.8553792,\n",
       "  0.85479134,\n",
       "  0.8535703,\n",
       "  0.84907705,\n",
       "  0.8542948],\n",
       " 'val_negatives': [23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666],\n",
       " 'val_positives': [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0],\n",
       " 'val_true_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22222222],\n",
       " 'val_true_negatives': [23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.666666,\n",
       "  23.555555,\n",
       "  23.333334,\n",
       "  22.555555,\n",
       "  22.222221],\n",
       " 'val_false_positives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.11111111,\n",
       "  0.33333334,\n",
       "  1.1111112,\n",
       "  1.4444444],\n",
       " 'val_false_negatives': [4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  4.0,\n",
       "  3.7777777],\n",
       " 'model': \"<class 'damage.models.cnn.CNN'>\",\n",
       " 'space': {'dense_units': 128,\n",
       "  'batch_size': 31,\n",
       "  'convolutional_layers': [{'kernel_size': [5, 5],\n",
       "    'pool_size': [4, 4],\n",
       "    'filters': 32,\n",
       "    'dropout': 0.17777777777777778,\n",
       "    'activation': 'relu'},\n",
       "   {'kernel_size': [5, 5],\n",
       "    'pool_size': [4, 4],\n",
       "    'filters': 64,\n",
       "    'dropout': 0.17777777777777778,\n",
       "    'activation': 'relu'}],\n",
       "  'epochs': 12,\n",
       "  'layer_type': 'vgg',\n",
       "  'class_weight': 1.15,\n",
       "  'learning_rate': 0.21209508879201905},\n",
       " 'features': 'example_daraa.p',\n",
       " 'num_batches_train': 19,\n",
       " 'num_batches_test': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
