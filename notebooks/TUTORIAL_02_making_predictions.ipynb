{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 02: Making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we learn how to make predictions using components explained in previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import logging\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "from damage.models import CNN\n",
    "from damage.data import DataStream, load_experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the features generated on the first notebook and the experiment results generated when validating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>annotation_date</th>\n",
       "      <th>damage_num</th>\n",
       "      <th>destroyed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">daraa</th>\n",
       "      <th>10080-8224</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.616861</td>\n",
       "      <td>36.122191</td>\n",
       "      <td>[[[99, 85, 74, 90, 65, 58], [99, 81, 74, 90, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208-8288</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.616517</td>\n",
       "      <td>36.122878</td>\n",
       "      <td>[[[123, 125, 123, 90, 61, 58], [107, 113, 115,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272-4768</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.635400</td>\n",
       "      <td>36.123221</td>\n",
       "      <td>[[[99, 73, 66, 41, 40, 41], [99, 73, 66, 41, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336-7904</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.618577</td>\n",
       "      <td>36.123565</td>\n",
       "      <td>[[[181, 190, 197, 132, 89, 74], [181, 186, 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400-8160</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.617204</td>\n",
       "      <td>36.123908</td>\n",
       "      <td>[[[99, 97, 99, 49, 45, 41], [82, 85, 82, 49, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            annotation_date  damage_num  destroyed   latitude  \\\n",
       "city  patch_id   date                                                           \n",
       "daraa 10080-8224 2017-02-07      2016-04-19         2.0        0.0  32.616861   \n",
       "      10208-8288 2017-02-07      2016-04-19         1.0        0.0  32.616517   \n",
       "      10272-4768 2017-02-07      2016-04-19         1.0        0.0  32.635400   \n",
       "      10336-7904 2017-02-07      2016-04-19         3.0        1.0  32.618577   \n",
       "      10400-8160 2017-02-07      2016-04-19         2.0        0.0  32.617204   \n",
       "\n",
       "                             longitude  \\\n",
       "city  patch_id   date                    \n",
       "daraa 10080-8224 2017-02-07  36.122191   \n",
       "      10208-8288 2017-02-07  36.122878   \n",
       "      10272-4768 2017-02-07  36.123221   \n",
       "      10336-7904 2017-02-07  36.123565   \n",
       "      10400-8160 2017-02-07  36.123908   \n",
       "\n",
       "                                                                         image  \n",
       "city  patch_id   date                                                           \n",
       "daraa 10080-8224 2017-02-07  [[[99, 85, 74, 90, 65, 58], [99, 81, 74, 90, 6...  \n",
       "      10208-8288 2017-02-07  [[[123, 125, 123, 90, 61, 58], [107, 113, 115,...  \n",
       "      10272-4768 2017-02-07  [[[99, 73, 66, 41, 40, 41], [99, 73, 66, 41, 4...  \n",
       "      10336-7904 2017-02-07  [[[181, 190, 197, 132, 89, 74], [181, 186, 189...  \n",
       "      10400-8160 2017-02-07  [[[99, 97, 99, 49, 45, 41], [82, 85, 82, 49, 4...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_pickle('../logs/features/example_daraa.p').dropna(subset=['destroyed'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>features</th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "      <th>model</th>\n",
       "      <th>name</th>\n",
       "      <th>negatives</th>\n",
       "      <th>num_batches_test</th>\n",
       "      <th>...</th>\n",
       "      <th>val_false_positives</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_negatives</th>\n",
       "      <th>val_positives</th>\n",
       "      <th>val_precision_negatives</th>\n",
       "      <th>val_precision_positives</th>\n",
       "      <th>val_recall_negatives</th>\n",
       "      <th>val_recall_positives</th>\n",
       "      <th>val_true_negatives</th>\n",
       "      <th>val_true_positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.4729064, 0.47947454, 0.500821, 0.5123153, 0...</td>\n",
       "      <td>[3.125, 2.9166667, 2.75, 2.8333333, 2.7083333,...</td>\n",
       "      <td>[10.25, 10.291667, 9.916667, 9.541667, 10.2083...</td>\n",
       "      <td>test_daraa.p</td>\n",
       "      <td>1563893402</td>\n",
       "      <td>[3.2779477617423525, 3.1167680101441633, 3.070...</td>\n",
       "      <td>&lt;class 'damage.models.cnn.CNN'&gt;</td>\n",
       "      <td>experiment_1563893402.json</td>\n",
       "      <td>[19.541666, 19.541666, 19.541666, 19.541666, 1...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[21.1, 20.7, 8.1, 21.1, 19.7, 9.0, 0.2]</td>\n",
       "      <td>[12.996690273284912, 12.751161861419678, 6.048...</td>\n",
       "      <td>[21.1, 21.1, 21.1, 21.1, 21.1, 21.1, 21.1]</td>\n",
       "      <td>[3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8]</td>\n",
       "      <td>[0.0, 0.39999995, 0.8420224, 0.0, 0.6833333, 0...</td>\n",
       "      <td>[0.15238461, 0.1548768, 0.13761905, 0.15238461...</td>\n",
       "      <td>[0.0, 0.018831167, 0.61601734, 0.0, 0.06623377...</td>\n",
       "      <td>[1.0, 1.0, 0.35833332, 1.0, 0.925, 0.43333334,...</td>\n",
       "      <td>[0.0, 0.4, 13.0, 0.0, 1.4, 12.1, 20.9]</td>\n",
       "      <td>[3.8, 3.8, 1.3, 3.8, 3.5, 1.6, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4664372, 0.4698795, 0.5043029, 0.4870912, 0...</td>\n",
       "      <td>[2.8333333, 3.0555556, 3.1666667, 2.8333333, 2...</td>\n",
       "      <td>[14.388889, 14.055555, 12.833333, 13.722222, 1...</td>\n",
       "      <td>test_daraa.p</td>\n",
       "      <td>1563900369</td>\n",
       "      <td>[7.747854771999812, 8.02643360738705, 7.339660...</td>\n",
       "      <td>&lt;class 'damage.models.cnn.CNN'&gt;</td>\n",
       "      <td>experiment_1563900369.json</td>\n",
       "      <td>[26.944445, 26.944445, 26.944445, 26.944445, 2...</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>[24.375, 24.125, 0.0, 24.375, 24.375, 21.25]</td>\n",
       "      <td>[12.010393381118774, 11.885567784309387, 3.342...</td>\n",
       "      <td>[24.375, 24.375, 24.375, 24.375, 24.375, 24.375]</td>\n",
       "      <td>[6.75, 6.75, 6.75, 6.75, 6.75, 6.75]</td>\n",
       "      <td>[0.0, 0.24999997, 0.78329134, 0.0, 0.0, 0.6500...</td>\n",
       "      <td>[0.21670869, 0.21851161, 0.0, 0.21033268, 0.21...</td>\n",
       "      <td>[0.0, 0.010416667, 1.0, 0.0, 0.0, 0.12770835]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 0.96428573, 1.0, 0.77678573]</td>\n",
       "      <td>[0.0, 0.25, 24.375, 0.0, 0.0, 3.125]</td>\n",
       "      <td>[6.75, 6.75, 0.0, 6.5, 6.75, 5.25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            accuracy  \\\n",
       "0  [0.4729064, 0.47947454, 0.500821, 0.5123153, 0...   \n",
       "1  [0.4664372, 0.4698795, 0.5043029, 0.4870912, 0...   \n",
       "\n",
       "                                     false_negatives  \\\n",
       "0  [3.125, 2.9166667, 2.75, 2.8333333, 2.7083333,...   \n",
       "1  [2.8333333, 3.0555556, 3.1666667, 2.8333333, 2...   \n",
       "\n",
       "                                     false_positives      features  \\\n",
       "0  [10.25, 10.291667, 9.916667, 9.541667, 10.2083...  test_daraa.p   \n",
       "1  [14.388889, 14.055555, 12.833333, 13.722222, 1...  test_daraa.p   \n",
       "\n",
       "           id                                               loss  \\\n",
       "0  1563893402  [3.2779477617423525, 3.1167680101441633, 3.070...   \n",
       "1  1563900369  [7.747854771999812, 8.02643360738705, 7.339660...   \n",
       "\n",
       "                             model                        name  \\\n",
       "0  <class 'damage.models.cnn.CNN'>  experiment_1563893402.json   \n",
       "1  <class 'damage.models.cnn.CNN'>  experiment_1563900369.json   \n",
       "\n",
       "                                           negatives  num_batches_test  ...  \\\n",
       "0  [19.541666, 19.541666, 19.541666, 19.541666, 1...                10  ...   \n",
       "1  [26.944445, 26.944445, 26.944445, 26.944445, 2...                 8  ...   \n",
       "\n",
       "                            val_false_positives  \\\n",
       "0       [21.1, 20.7, 8.1, 21.1, 19.7, 9.0, 0.2]   \n",
       "1  [24.375, 24.125, 0.0, 24.375, 24.375, 21.25]   \n",
       "\n",
       "                                            val_loss  \\\n",
       "0  [12.996690273284912, 12.751161861419678, 6.048...   \n",
       "1  [12.010393381118774, 11.885567784309387, 3.342...   \n",
       "\n",
       "                                      val_negatives  \\\n",
       "0        [21.1, 21.1, 21.1, 21.1, 21.1, 21.1, 21.1]   \n",
       "1  [24.375, 24.375, 24.375, 24.375, 24.375, 24.375]   \n",
       "\n",
       "                          val_positives  \\\n",
       "0   [3.8, 3.8, 3.8, 3.8, 3.8, 3.8, 3.8]   \n",
       "1  [6.75, 6.75, 6.75, 6.75, 6.75, 6.75]   \n",
       "\n",
       "                             val_precision_negatives  \\\n",
       "0  [0.0, 0.39999995, 0.8420224, 0.0, 0.6833333, 0...   \n",
       "1  [0.0, 0.24999997, 0.78329134, 0.0, 0.0, 0.6500...   \n",
       "\n",
       "                             val_precision_positives  \\\n",
       "0  [0.15238461, 0.1548768, 0.13761905, 0.15238461...   \n",
       "1  [0.21670869, 0.21851161, 0.0, 0.21033268, 0.21...   \n",
       "\n",
       "                                val_recall_negatives  \\\n",
       "0  [0.0, 0.018831167, 0.61601734, 0.0, 0.06623377...   \n",
       "1      [0.0, 0.010416667, 1.0, 0.0, 0.0, 0.12770835]   \n",
       "\n",
       "                                val_recall_positives  \\\n",
       "0  [1.0, 1.0, 0.35833332, 1.0, 0.925, 0.43333334,...   \n",
       "1       [1.0, 1.0, 0.0, 0.96428573, 1.0, 0.77678573]   \n",
       "\n",
       "                       val_true_negatives                   val_true_positives  \n",
       "0  [0.0, 0.4, 13.0, 0.0, 1.4, 12.1, 20.9]  [3.8, 3.8, 1.3, 3.8, 3.5, 1.6, 0.0]  \n",
       "1    [0.0, 0.25, 24.375, 0.0, 0.0, 3.125]   [6.75, 6.75, 0.0, 6.5, 6.75, 5.25]  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENTS_PATH = '../logs/experiments/'\n",
    "experiment_results = load_experiment_results(EXPERIMENTS_PATH)\n",
    "experiment_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accuracy', 'false_negatives', 'false_positives', 'features', 'id',\n",
       "       'loss', 'model', 'name', 'negatives', 'num_batches_test',\n",
       "       'num_batches_train', 'positives', 'precision_negatives',\n",
       "       'precision_positives', 'recall_negatives', 'recall_positives', 'space',\n",
       "       'true_negatives', 'true_positives', 'val_accuracy',\n",
       "       'val_false_negatives', 'val_false_positives', 'val_loss',\n",
       "       'val_negatives', 'val_positives', 'val_precision_negatives',\n",
       "       'val_precision_positives', 'val_recall_negatives',\n",
       "       'val_recall_positives', 'val_true_negatives', 'val_true_positives'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.0, 0.96428573, 1.0, 0.77678573]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results.loc[1,'val_recall_positives']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose the results according to some logic (e.g. best results, last experiment...). In this case, we will just take the last experiment, which we can find using the experiment id column (timestamp of generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_units': 128,\n",
       " 'batch_size': 33,\n",
       " 'convolutional_layers': [{'kernel_size': [7, 7],\n",
       "   'pool_size': [6, 6],\n",
       "   'filters': 32,\n",
       "   'dropout': 0.33333333333333337,\n",
       "   'activation': 'relu'},\n",
       "  {'kernel_size': [7, 7],\n",
       "   'pool_size': [6, 6],\n",
       "   'filters': 64,\n",
       "   'dropout': 0.33333333333333337,\n",
       "   'activation': 'relu'},\n",
       "  {'kernel_size': [7, 7],\n",
       "   'pool_size': [6, 6],\n",
       "   'filters': 128,\n",
       "   'dropout': 0.33333333333333337,\n",
       "   'activation': 'relu'}],\n",
       " 'epochs': 6,\n",
       " 'layer_type': 'cnn',\n",
       " 'class_weight': 1.15,\n",
       " 'learning_rate': 0.0017575106248547913}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = CNN\n",
    "experiment_results_single_model = experiment_results.loc[experiment_results['model'] == str(Model)]\n",
    "space = experiment_results_single_model.loc[experiment_results_single_model['id'].idxmax(), 'space']\n",
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = experiment_results_single_model.loc[experiment_results_single_model['id'].idxmax(), 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 1563900369\n",
      "With space {'dense_units': 128, 'batch_size': 33, 'convolutional_layers': [{'kernel_size': [7, 7], 'pool_size': [6, 6], 'filters': 32, 'dropout': 0.33333333333333337, 'activation': 'relu'}, {'kernel_size': [7, 7], 'pool_size': [6, 6], 'filters': 64, 'dropout': 0.33333333333333337, 'activation': 'relu'}, {'kernel_size': [7, 7], 'pool_size': [6, 6], 'filters': 128, 'dropout': 0.33333333333333337, 'activation': 'relu'}], 'epochs': 6, 'layer_type': 'cnn', 'class_weight': 1.15, 'learning_rate': 0.0017575106248547913}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0723 19:37:16.603396 4583605696 hdf5_format.py:266] Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('Loading model {}'.format(identifier))\n",
    "    print('With space {}'.format(space))\n",
    "    model = load_model('../logs/models/model_{}.h5'.format(identifier))\n",
    "    print('Model loaded')\n",
    "except Exception as e:\n",
    "    raise e('Error loading model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0723 19:37:21.614492 4583605696 deprecation.py:323] From /Users/jordi/anaconda3/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:410: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "test_generator = DataStream._get_index_generator(features, space['batch_size'], KFold)\n",
    "num_batches_test = len(test_generator)\n",
    "test_generator = DataStream.get_test_data_generator_from_index(features['image'], test_generator)\n",
    "test_dataset = Dataset.from_generator(lambda: test_generator, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>patch_id</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">daraa</th>\n",
       "      <th>10080-8224</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>3.097520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10208-8288</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>7.960730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272-4768</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>7.992837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336-7904</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400-8160</th>\n",
       "      <th>2017-02-07</th>\n",
       "      <td>1.887757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             prediction\n",
       "city  patch_id   date                  \n",
       "daraa 10080-8224 2017-02-07    3.097520\n",
       "      10208-8288 2017-02-07    7.960730\n",
       "      10272-4768 2017-02-07    7.992837\n",
       "      10336-7904 2017-02-07    0.000000\n",
       "      10400-8160 2017-02-07    1.887757"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "print('Generating predictions')\n",
    "predictions = model.predict_generator(test_dataset, steps=num_batches_test)\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    'prediction': predictions.reshape(-1),\n",
    "}, index=features.index)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store predictions on file: ../logs/predictions/prediction_1563904454.p\n"
     ]
    }
   ],
   "source": [
    "RESULTS_PATH = '../logs/predictions'\n",
    "file_name = '{}/prediction_{}.p'.format(RESULTS_PATH, round(time()))\n",
    "predictions.to_pickle(file_name)\n",
    "print('Store predictions on file: {}'.format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_index_generator, test_index_generator = data_stream.split_by_patch_id(features['image'], features['destroyed'])\n",
    "# train_generator = data_stream.get_data_generator_from_index([features['image'], features['destroyed']],\n",
    "#                                                             train_index_generator)\n",
    "# test_indices = list(test_index_generator)\n",
    "# test_generator = data_stream.get_data_generator_from_index([features['image']], test_indices)\n",
    "\n",
    "# num_batches = ceil(len(features) / space['batch_size'])\n",
    "# model = Model(**space)\n",
    "# model.fit_generator(train_generator,\n",
    "#                     steps_per_epoch=num_batches,\n",
    "#                     validation_steps=1,\n",
    "#                     **space)\n",
    "\n",
    "# predictions = model.predict_generator(test_generator, steps=len(test_indices))\n",
    "# predictions = pd.DataFrame({\n",
    "#     'prediction': predictions[:, 1],\n",
    "# }, index=reduce(lambda l, r: l.union(r), test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_PATH = '../logs/predictions'\n",
    "# file_name = '{}/prediction_test.p'.format(RESULTS_PATH)\n",
    "# predictions.to_pickle(file_name)\n",
    "# print('Stored predictions on file: {}'.format(file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
